{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is the Swiss-Multipurpose Knife for Data Analysis in Python. With Pandas dealing with data-analysis is easy and simple but there are some things you need to get your head around first as Data-Frames and Data-Series. \n",
    "\n",
    "The tutorial provides a compact introduction to Pandas for beginners for I/O, data visualisation, statistical data analysis and aggregation within Jupiter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Brief Introduction to Pandas\n",
    "\n",
    "Pandas builds on top of two main data structures: **Data Frame** and **Series**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Frame _from the outside_\n",
    "\n",
    "<img src=\"./images/df_outside.png\" width=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Frame _from the inside_\n",
    "\n",
    "<img src=\"./images/df_inside.png\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Frame vs Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Numpy Array\n",
    "\n",
    "<img src=\"./images/ndarray.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Pandas Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/df_inside_numpy.png\" width=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Pandas in a Nutshell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name,birthday,customer,orderdate,product,units,unitprice\n",
      "Pasquale,1967-09-02,Electronics Inc,2016-07-17 13:48:03.156566,Thriller record,2,13.27\n",
      "India,1968-12-13,Electronics Resource Group,2016-07-06 13:48:03.156596,Corolla,26,24458.69\n",
      "Wayne,1992-09-10,East Application Contract Inc,2016-07-22 13:48:03.156618,Rubik’s Cube,41,15.79\n",
      "Cori,1986-11-05,Signal Industries,2016-07-23 13:48:03.156638,iPhone,16,584.01\n",
      "Chang,1972-04-23,Star Alpha Industries,2016-07-16 13:48:03.156657,Harry Potter book,4,25.69\n",
      "Weldon,1953-03-17,Network Application Co,2016-07-22 13:48:03.156678,Lipitor,1,11.22\n",
      "Sung,1977-10-23,Omega Pacific Future Incorporated,2016-07-09 13:48:03.156698,PlayStation,25,294.9\n",
      "Emily,1982-07-02,Medicine Incorporated,2016-07-16 13:48:03.156717,Thriller record,5,18.27\n",
      "Cornell,1963-07-02,Technology Direct Star Limited,2016-07-08 13:48:03.156735,Rubik’s Cube,35,15.98\n"
     ]
    }
   ],
   "source": [
    "!head ./data/blooth_sales_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv('./data/blooth_sales_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's explore our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>birthday</th>\n",
       "      <th>customer</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>product</th>\n",
       "      <th>units</th>\n",
       "      <th>unitprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pasquale</td>\n",
       "      <td>1967-09-02</td>\n",
       "      <td>Electronics Inc</td>\n",
       "      <td>2016-07-17 13:48:03.156566</td>\n",
       "      <td>Thriller record</td>\n",
       "      <td>2</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>1968-12-13</td>\n",
       "      <td>Electronics Resource Group</td>\n",
       "      <td>2016-07-06 13:48:03.156596</td>\n",
       "      <td>Corolla</td>\n",
       "      <td>26</td>\n",
       "      <td>24458.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>1992-09-10</td>\n",
       "      <td>East Application Contract Inc</td>\n",
       "      <td>2016-07-22 13:48:03.156618</td>\n",
       "      <td>Rubik’s Cube</td>\n",
       "      <td>41</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cori</td>\n",
       "      <td>1986-11-05</td>\n",
       "      <td>Signal Industries</td>\n",
       "      <td>2016-07-23 13:48:03.156638</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>16</td>\n",
       "      <td>584.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chang</td>\n",
       "      <td>1972-04-23</td>\n",
       "      <td>Star Alpha Industries</td>\n",
       "      <td>2016-07-16 13:48:03.156657</td>\n",
       "      <td>Harry Potter book</td>\n",
       "      <td>4</td>\n",
       "      <td>25.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Weldon</td>\n",
       "      <td>1953-03-17</td>\n",
       "      <td>Network Application Co</td>\n",
       "      <td>2016-07-22 13:48:03.156678</td>\n",
       "      <td>Lipitor</td>\n",
       "      <td>1</td>\n",
       "      <td>11.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sung</td>\n",
       "      <td>1977-10-23</td>\n",
       "      <td>Omega Pacific Future Incorporated</td>\n",
       "      <td>2016-07-09 13:48:03.156698</td>\n",
       "      <td>PlayStation</td>\n",
       "      <td>25</td>\n",
       "      <td>294.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Emily</td>\n",
       "      <td>1982-07-02</td>\n",
       "      <td>Medicine Incorporated</td>\n",
       "      <td>2016-07-16 13:48:03.156717</td>\n",
       "      <td>Thriller record</td>\n",
       "      <td>5</td>\n",
       "      <td>18.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cornell</td>\n",
       "      <td>1963-07-02</td>\n",
       "      <td>Technology Direct Star Limited</td>\n",
       "      <td>2016-07-08 13:48:03.156735</td>\n",
       "      <td>Rubik’s Cube</td>\n",
       "      <td>35</td>\n",
       "      <td>15.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ervin</td>\n",
       "      <td>1977-10-14</td>\n",
       "      <td>Provider Agency</td>\n",
       "      <td>2016-07-19 13:48:03.156754</td>\n",
       "      <td>Star Wars</td>\n",
       "      <td>24</td>\n",
       "      <td>11.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name    birthday                           customer  \\\n",
       "0  Pasquale  1967-09-02                    Electronics Inc   \n",
       "1     India  1968-12-13         Electronics Resource Group   \n",
       "2     Wayne  1992-09-10      East Application Contract Inc   \n",
       "3      Cori  1986-11-05                  Signal Industries   \n",
       "4     Chang  1972-04-23              Star Alpha Industries   \n",
       "5    Weldon  1953-03-17             Network Application Co   \n",
       "6      Sung  1977-10-23  Omega Pacific Future Incorporated   \n",
       "7     Emily  1982-07-02              Medicine Incorporated   \n",
       "8   Cornell  1963-07-02     Technology Direct Star Limited   \n",
       "9     Ervin  1977-10-14                    Provider Agency   \n",
       "\n",
       "                    orderdate            product  units  unitprice  \n",
       "0  2016-07-17 13:48:03.156566    Thriller record      2      13.27  \n",
       "1  2016-07-06 13:48:03.156596            Corolla     26   24458.69  \n",
       "2  2016-07-22 13:48:03.156618       Rubik’s Cube     41      15.79  \n",
       "3  2016-07-23 13:48:03.156638             iPhone     16     584.01  \n",
       "4  2016-07-16 13:48:03.156657  Harry Potter book      4      25.69  \n",
       "5  2016-07-22 13:48:03.156678            Lipitor      1      11.22  \n",
       "6  2016-07-09 13:48:03.156698        PlayStation     25     294.90  \n",
       "7  2016-07-16 13:48:03.156717    Thriller record      5      18.27  \n",
       "8  2016-07-08 13:48:03.156735       Rubik’s Cube     35      15.98  \n",
       "9  2016-07-19 13:48:03.156754          Star Wars     24      11.50  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Let's see what we have got now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sales_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Inspect your DataFrame with pandas methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>birthday</th>\n",
       "      <th>customer</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>product</th>\n",
       "      <th>units</th>\n",
       "      <th>unitprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pasquale</td>\n",
       "      <td>1967-09-02</td>\n",
       "      <td>Electronics Inc</td>\n",
       "      <td>2016-07-17 13:48:03.156566</td>\n",
       "      <td>Thriller record</td>\n",
       "      <td>2</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>1968-12-13</td>\n",
       "      <td>Electronics Resource Group</td>\n",
       "      <td>2016-07-06 13:48:03.156596</td>\n",
       "      <td>Corolla</td>\n",
       "      <td>26</td>\n",
       "      <td>24458.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>1992-09-10</td>\n",
       "      <td>East Application Contract Inc</td>\n",
       "      <td>2016-07-22 13:48:03.156618</td>\n",
       "      <td>Rubik’s Cube</td>\n",
       "      <td>41</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cori</td>\n",
       "      <td>1986-11-05</td>\n",
       "      <td>Signal Industries</td>\n",
       "      <td>2016-07-23 13:48:03.156638</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>16</td>\n",
       "      <td>584.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chang</td>\n",
       "      <td>1972-04-23</td>\n",
       "      <td>Star Alpha Industries</td>\n",
       "      <td>2016-07-16 13:48:03.156657</td>\n",
       "      <td>Harry Potter book</td>\n",
       "      <td>4</td>\n",
       "      <td>25.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name    birthday                       customer  \\\n",
       "0  Pasquale  1967-09-02                Electronics Inc   \n",
       "1     India  1968-12-13     Electronics Resource Group   \n",
       "2     Wayne  1992-09-10  East Application Contract Inc   \n",
       "3      Cori  1986-11-05              Signal Industries   \n",
       "4     Chang  1972-04-23          Star Alpha Industries   \n",
       "\n",
       "                    orderdate            product  units  unitprice  \n",
       "0  2016-07-17 13:48:03.156566    Thriller record      2      13.27  \n",
       "1  2016-07-06 13:48:03.156596            Corolla     26   24458.69  \n",
       "2  2016-07-22 13:48:03.156618       Rubik’s Cube     41      15.79  \n",
       "3  2016-07-23 13:48:03.156638             iPhone     16     584.01  \n",
       "4  2016-07-16 13:48:03.156657  Harry Potter book      4      25.69  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>birthday</th>\n",
       "      <th>customer</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>product</th>\n",
       "      <th>units</th>\n",
       "      <th>unitprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>1952-12-08</td>\n",
       "      <td>Application Industries</td>\n",
       "      <td>2016-07-21 13:48:03.177885</td>\n",
       "      <td>Harry Potter book</td>\n",
       "      <td>39</td>\n",
       "      <td>24.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Rudolph</td>\n",
       "      <td>1959-10-15</td>\n",
       "      <td>Network Software West Inc</td>\n",
       "      <td>2016-07-19 13:48:03.177903</td>\n",
       "      <td>Rubik’s Cube</td>\n",
       "      <td>9</td>\n",
       "      <td>15.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Annmarie</td>\n",
       "      <td>1982-06-04</td>\n",
       "      <td>Atlantic Corporation</td>\n",
       "      <td>2016-07-13 13:48:03.177924</td>\n",
       "      <td>Thriller record</td>\n",
       "      <td>19</td>\n",
       "      <td>9.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Chang</td>\n",
       "      <td>1984-02-05</td>\n",
       "      <td>Venture Alpha Corporation</td>\n",
       "      <td>2016-07-13 13:48:03.177943</td>\n",
       "      <td>Harry Potter book</td>\n",
       "      <td>24</td>\n",
       "      <td>28.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Ervin</td>\n",
       "      <td>1977-10-14</td>\n",
       "      <td>Provider Agency</td>\n",
       "      <td>2016-07-09 13:48:03.177962</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>39</td>\n",
       "      <td>663.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name    birthday                   customer  \\\n",
       "995     Ethan  1952-12-08     Application Industries   \n",
       "996   Rudolph  1959-10-15  Network Software West Inc   \n",
       "997  Annmarie  1982-06-04       Atlantic Corporation   \n",
       "998     Chang  1984-02-05  Venture Alpha Corporation   \n",
       "999     Ervin  1977-10-14            Provider Agency   \n",
       "\n",
       "                      orderdate            product  units  unitprice  \n",
       "995  2016-07-21 13:48:03.177885  Harry Potter book     39      24.40  \n",
       "996  2016-07-19 13:48:03.177903       Rubik’s Cube      9      15.11  \n",
       "997  2016-07-13 13:48:03.177924    Thriller record     19       9.16  \n",
       "998  2016-07-13 13:48:03.177943  Harry Potter book     24      28.21  \n",
       "999  2016-07-09 13:48:03.177962             iPhone     39     663.83  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      "name         1000 non-null object\n",
      "birthday     1000 non-null object\n",
      "customer     1000 non-null object\n",
      "orderdate    1000 non-null object\n",
      "product      1000 non-null object\n",
      "units        1000 non-null int64\n",
      "unitprice    1000 non-null float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sales_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**note: floats and ints were detected automatically but date(time) are still strings objects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *columns*\n",
    "* count rows\n",
    "* data types (numpy)\n",
    "* memenory used\n",
    "\n",
    "**`Strings`** are stored in **`pandas`** as **`object`**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_date_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthousands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mb'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipfooter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_footer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_recarray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompact_ints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_unsigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat_precision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Read CSV (comma-separated) file into DataFrame\n",
       "\n",
       "Also supports optionally iterating or breaking of the file\n",
       "into chunks.\n",
       "\n",
       "Additional help can be found in the `online docs for IO Tools\n",
       "<http://pandas.pydata.org/pandas-docs/stable/io.html>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filepath_or_buffer : str, pathlib.Path, py._path.local.LocalPath or any object with a read() method (such as a file handle or StringIO)\n",
       "    The string could be a URL. Valid URL schemes include http, ftp, s3, and\n",
       "    file. For file URLs, a host is expected. For instance, a local file could\n",
       "    be file ://localhost/path/to/table.csv\n",
       "sep : str, default ','\n",
       "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
       "    the separator, but the Python parsing engine can, meaning the latter will\n",
       "    be used and automatically detect the separator by Python's builtin sniffer\n",
       "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
       "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
       "    will also force the use of the Python parsing engine. Note that regex\n",
       "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``\n",
       "delimiter : str, default ``None``\n",
       "    Alternative argument name for sep.\n",
       "delim_whitespace : boolean, default False\n",
       "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
       "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
       "    is set to True, nothing should be passed in for the ``delimiter``\n",
       "    parameter.\n",
       "\n",
       "    .. versionadded:: 0.18.1 support for the Python parser.\n",
       "\n",
       "header : int or list of ints, default 'infer'\n",
       "    Row number(s) to use as the column names, and the start of the\n",
       "    data.  Default behavior is to infer the column names: if no names\n",
       "    are passed the behavior is identical to ``header=0`` and column\n",
       "    names are inferred from the first line of the file, if column\n",
       "    names are passed explicitly then the behavior is identical to\n",
       "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
       "    replace existing names. The header can be a list of integers that\n",
       "    specify row locations for a multi-index on the columns\n",
       "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
       "    skipped (e.g. 2 in this example is skipped). Note that this\n",
       "    parameter ignores commented lines and empty lines if\n",
       "    ``skip_blank_lines=True``, so header=0 denotes the first line of\n",
       "    data rather than the first line of the file.\n",
       "names : array-like, default None\n",
       "    List of column names to use. If file contains no header row, then you\n",
       "    should explicitly pass header=None. Duplicates in this list will cause\n",
       "    a ``UserWarning`` to be issued.\n",
       "index_col : int or sequence or False, default None\n",
       "    Column to use as the row labels of the DataFrame. If a sequence is given, a\n",
       "    MultiIndex is used. If you have a malformed file with delimiters at the end\n",
       "    of each line, you might consider index_col=False to force pandas to _not_\n",
       "    use the first column as the index (row names)\n",
       "usecols : array-like or callable, default None\n",
       "    Return a subset of the columns. If array-like, all elements must either\n",
       "    be positional (i.e. integer indices into the document columns) or strings\n",
       "    that correspond to column names provided either by the user in `names` or\n",
       "    inferred from the document header row(s). For example, a valid array-like\n",
       "    `usecols` parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'].\n",
       "\n",
       "    If callable, the callable function will be evaluated against the column\n",
       "    names, returning names where the callable function evaluates to True. An\n",
       "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
       "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
       "    parsing time and lower memory usage.\n",
       "as_recarray : boolean, default False\n",
       "    .. deprecated:: 0.19.0\n",
       "       Please call `pd.read_csv(...).to_records()` instead.\n",
       "\n",
       "    Return a NumPy recarray instead of a DataFrame after parsing the data.\n",
       "    If set to True, this option takes precedence over the `squeeze` parameter.\n",
       "    In addition, as row indices are not available in such a format, the\n",
       "    `index_col` parameter will be ignored.\n",
       "squeeze : boolean, default False\n",
       "    If the parsed data only contains one column then return a Series\n",
       "prefix : str, default None\n",
       "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
       "mangle_dupe_cols : boolean, default True\n",
       "    Duplicate columns will be specified as 'X.0'...'X.N', rather than\n",
       "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
       "    are duplicate names in the columns.\n",
       "dtype : Type name or dict of column -> type, default None\n",
       "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
       "    Use `str` or `object` to preserve and not interpret dtype.\n",
       "    If converters are specified, they will be applied INSTEAD\n",
       "    of dtype conversion.\n",
       "engine : {'c', 'python'}, optional\n",
       "    Parser engine to use. The C engine is faster while the python engine is\n",
       "    currently more feature-complete.\n",
       "converters : dict, default None\n",
       "    Dict of functions for converting values in certain columns. Keys can either\n",
       "    be integers or column labels\n",
       "true_values : list, default None\n",
       "    Values to consider as True\n",
       "false_values : list, default None\n",
       "    Values to consider as False\n",
       "skipinitialspace : boolean, default False\n",
       "    Skip spaces after delimiter.\n",
       "skiprows : list-like or integer or callable, default None\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
       "    at the start of the file.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the row\n",
       "    indices, returning True if the row should be skipped and False otherwise.\n",
       "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
       "skipfooter : int, default 0\n",
       "    Number of lines at bottom of file to skip (Unsupported with engine='c')\n",
       "skip_footer : int, default 0\n",
       "    .. deprecated:: 0.19.0\n",
       "       Use the `skipfooter` parameter instead, as they are identical\n",
       "nrows : int, default None\n",
       "    Number of rows of file to read. Useful for reading pieces of large files\n",
       "na_values : scalar, str, list-like, or dict, default None\n",
       "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
       "    per-column NA values.  By default the following values are interpreted as\n",
       "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
       "    '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan',\n",
       "    'null'.\n",
       "keep_default_na : bool, default True\n",
       "    If na_values are specified and keep_default_na is False the default NaN\n",
       "    values are overridden, otherwise they're appended to.\n",
       "na_filter : boolean, default True\n",
       "    Detect missing value markers (empty strings and the value of na_values). In\n",
       "    data without any NAs, passing na_filter=False can improve the performance\n",
       "    of reading a large file\n",
       "verbose : boolean, default False\n",
       "    Indicate number of NA values placed in non-numeric columns\n",
       "skip_blank_lines : boolean, default True\n",
       "    If True, skip over blank lines rather than interpreting as NaN values\n",
       "parse_dates : boolean or list of ints or names or list of lists or dict, default False\n",
       "\n",
       "    * boolean. If True -> try parsing the index.\n",
       "    * list of ints or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
       "      a single date column.\n",
       "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call result\n",
       "      'foo'\n",
       "\n",
       "    If a column or index contains an unparseable date, the entire column or\n",
       "    index will be returned unaltered as an object data type. For non-standard\n",
       "    datetime parsing, use ``pd.to_datetime`` after ``pd.read_csv``\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "infer_datetime_format : boolean, default False\n",
       "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
       "    format of the datetime strings in the columns, and if it can be inferred,\n",
       "    switch to a faster method of parsing them. In some cases this can increase\n",
       "    the parsing speed by 5-10x.\n",
       "keep_date_col : boolean, default False\n",
       "    If True and `parse_dates` specifies combining multiple columns then\n",
       "    keep the original columns.\n",
       "date_parser : function, default None\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by `parse_dates` into a single array\n",
       "    and pass that; and 3) call `date_parser` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
       "    arguments.\n",
       "dayfirst : boolean, default False\n",
       "    DD/MM format dates, international and European format\n",
       "iterator : boolean, default False\n",
       "    Return TextFileReader object for iteration or getting chunks with\n",
       "    ``get_chunk()``.\n",
       "chunksize : int, default None\n",
       "    Return TextFileReader object for iteration.\n",
       "    See the `IO Tools docs\n",
       "    <http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
       "    for more information on ``iterator`` and ``chunksize``.\n",
       "compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer' and\n",
       "    `filepath_or_buffer` is path-like, then detect compression from the\n",
       "    following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
       "    decompression). If using 'zip', the ZIP file must contain only one data\n",
       "    file to be read in. Set to None for no decompression.\n",
       "\n",
       "    .. versionadded:: 0.18.1 support for 'zip' and 'xz' compression.\n",
       "\n",
       "thousands : str, default None\n",
       "    Thousands separator\n",
       "decimal : str, default '.'\n",
       "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
       "float_precision : string, default None\n",
       "    Specifies which converter the C engine should use for floating-point\n",
       "    values. The options are `None` for the ordinary converter,\n",
       "    `high` for the high-precision converter, and `round_trip` for the\n",
       "    round-trip converter.\n",
       "lineterminator : str (length 1), default None\n",
       "    Character to break file into lines. Only valid with C parser.\n",
       "quotechar : str (length 1), optional\n",
       "    The character used to denote the start and end of a quoted item. Quoted\n",
       "    items can include the delimiter and it will be ignored.\n",
       "quoting : int or csv.QUOTE_* instance, default 0\n",
       "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
       "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
       "doublequote : boolean, default ``True``\n",
       "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
       "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
       "   field as a single ``quotechar`` element.\n",
       "escapechar : str (length 1), default None\n",
       "    One-character string used to escape delimiter when quoting is QUOTE_NONE.\n",
       "comment : str, default None\n",
       "    Indicates remainder of line should not be parsed. If found at the beginning\n",
       "    of a line, the line will be ignored altogether. This parameter must be a\n",
       "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
       "    fully commented lines are ignored by the parameter `header` but not by\n",
       "    `skiprows`. For example, if comment='#', parsing '#empty\\na,b,c\\n1,2,3'\n",
       "    with `header=0` will result in 'a,b,c' being\n",
       "    treated as the header.\n",
       "encoding : str, default None\n",
       "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
       "    standard encodings\n",
       "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_\n",
       "dialect : str or csv.Dialect instance, default None\n",
       "    If provided, this parameter will override values (default or not) for the\n",
       "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
       "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
       "    override values, a ParserWarning will be issued. See csv.Dialect\n",
       "    documentation for more details.\n",
       "tupleize_cols : boolean, default False\n",
       "    .. deprecated:: 0.21.0\n",
       "       This argument will be removed and will always convert to MultiIndex\n",
       "\n",
       "    Leave a list of tuples on columns as is (default is to convert to\n",
       "    a MultiIndex on the columns)\n",
       "error_bad_lines : boolean, default True\n",
       "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
       "    default cause an exception to be raised, and no DataFrame will be returned.\n",
       "    If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
       "    returned.\n",
       "warn_bad_lines : boolean, default True\n",
       "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
       "    \"bad line\" will be output.\n",
       "low_memory : boolean, default True\n",
       "    Internally process the file in chunks, resulting in lower memory use\n",
       "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
       "    types either set False, or specify the type with the `dtype` parameter.\n",
       "    Note that the entire file is read into a single DataFrame regardless,\n",
       "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
       "    (Only valid with C parser)\n",
       "buffer_lines : int, default None\n",
       "    .. deprecated:: 0.19.0\n",
       "       This argument is not respected by the parser\n",
       "compact_ints : boolean, default False\n",
       "    .. deprecated:: 0.19.0\n",
       "       Argument moved to ``pd.to_numeric``\n",
       "\n",
       "    If compact_ints is True, then for any column that is of integer dtype,\n",
       "    the parser will attempt to cast it as the smallest integer dtype possible,\n",
       "    either signed or unsigned depending on the specification from the\n",
       "    `use_unsigned` parameter.\n",
       "use_unsigned : boolean, default False\n",
       "    .. deprecated:: 0.19.0\n",
       "       Argument moved to ``pd.to_numeric``\n",
       "\n",
       "    If integer columns are being compacted (i.e. `compact_ints=True`), specify\n",
       "    whether the column should be compacted to the smallest signed or unsigned\n",
       "    integer dtype.\n",
       "memory_map : boolean, default False\n",
       "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
       "    directly onto memory and access the data directly from there. Using this\n",
       "    option can improve performance because there is no longer any I/O overhead.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "result : DataFrame or TextParser\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**`pandas.read_csv`** has more than 50 parameters to customize imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example dates can be parsed automatically.\n",
    "\n",
    "> **`parse_dates`** a list of columns to parse for dates.\n",
    "\n",
    "This is only one of multiple options to customize imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      "name         1000 non-null object\n",
      "birthday     1000 non-null datetime64[ns]\n",
      "customer     1000 non-null object\n",
      "orderdate    1000 non-null datetime64[ns]\n",
      "product      1000 non-null object\n",
      "units        1000 non-null int64\n",
      "unitprice    1000 non-null float64\n",
      "dtypes: datetime64[ns](2), float64(1), int64(1), object(3)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sales_data = pd.read_csv('./data/blooth_sales_data.csv',\n",
    "                         parse_dates=['birthday', 'orderdate']\n",
    "                        )\n",
    "sales_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>birthday</th>\n",
       "      <th>customer</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>product</th>\n",
       "      <th>units</th>\n",
       "      <th>unitprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pasquale</td>\n",
       "      <td>1967-09-02</td>\n",
       "      <td>Electronics Inc</td>\n",
       "      <td>2016-07-17 13:48:03.156566</td>\n",
       "      <td>Thriller record</td>\n",
       "      <td>2</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>1968-12-13</td>\n",
       "      <td>Electronics Resource Group</td>\n",
       "      <td>2016-07-06 13:48:03.156596</td>\n",
       "      <td>Corolla</td>\n",
       "      <td>26</td>\n",
       "      <td>24458.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>1992-09-10</td>\n",
       "      <td>East Application Contract Inc</td>\n",
       "      <td>2016-07-22 13:48:03.156618</td>\n",
       "      <td>Rubik’s Cube</td>\n",
       "      <td>41</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cori</td>\n",
       "      <td>1986-11-05</td>\n",
       "      <td>Signal Industries</td>\n",
       "      <td>2016-07-23 13:48:03.156638</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>16</td>\n",
       "      <td>584.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chang</td>\n",
       "      <td>1972-04-23</td>\n",
       "      <td>Star Alpha Industries</td>\n",
       "      <td>2016-07-16 13:48:03.156657</td>\n",
       "      <td>Harry Potter book</td>\n",
       "      <td>4</td>\n",
       "      <td>25.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   birthday                       customer  \\\n",
       "0  Pasquale 1967-09-02                Electronics Inc   \n",
       "1     India 1968-12-13     Electronics Resource Group   \n",
       "2     Wayne 1992-09-10  East Application Contract Inc   \n",
       "3      Cori 1986-11-05              Signal Industries   \n",
       "4     Chang 1972-04-23          Star Alpha Industries   \n",
       "\n",
       "                   orderdate            product  units  unitprice  \n",
       "0 2016-07-17 13:48:03.156566    Thriller record      2      13.27  \n",
       "1 2016-07-06 13:48:03.156596            Corolla     26   24458.69  \n",
       "2 2016-07-22 13:48:03.156618       Rubik’s Cube     41      15.79  \n",
       "3 2016-07-23 13:48:03.156638             iPhone     16     584.01  \n",
       "4 2016-07-16 13:48:03.156657  Harry Potter book      4      25.69  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The auto date parser is US date friendly by default -> month first! MM/DD/YYYY add *dayfirst=True* for international and European format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>birthday</th>\n",
       "      <th>customer</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>product</th>\n",
       "      <th>units</th>\n",
       "      <th>unitprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pasquale</td>\n",
       "      <td>1967-09-02</td>\n",
       "      <td>Electronics Inc</td>\n",
       "      <td>2016-07-17 13:48:03.156566</td>\n",
       "      <td>Thriller record</td>\n",
       "      <td>2</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>1968-12-13</td>\n",
       "      <td>Electronics Resource Group</td>\n",
       "      <td>2016-07-06 13:48:03.156596</td>\n",
       "      <td>Corolla</td>\n",
       "      <td>26</td>\n",
       "      <td>24458.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>1992-09-10</td>\n",
       "      <td>East Application Contract Inc</td>\n",
       "      <td>2016-07-22 13:48:03.156618</td>\n",
       "      <td>Rubik’s Cube</td>\n",
       "      <td>41</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cori</td>\n",
       "      <td>1986-11-05</td>\n",
       "      <td>Signal Industries</td>\n",
       "      <td>2016-07-23 13:48:03.156638</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>16</td>\n",
       "      <td>584.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chang</td>\n",
       "      <td>1972-04-23</td>\n",
       "      <td>Star Alpha Industries</td>\n",
       "      <td>2016-07-16 13:48:03.156657</td>\n",
       "      <td>Harry Potter book</td>\n",
       "      <td>4</td>\n",
       "      <td>25.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   birthday                       customer  \\\n",
       "0  Pasquale 1967-09-02                Electronics Inc   \n",
       "1     India 1968-12-13     Electronics Resource Group   \n",
       "2     Wayne 1992-09-10  East Application Contract Inc   \n",
       "3      Cori 1986-11-05              Signal Industries   \n",
       "4     Chang 1972-04-23          Star Alpha Industries   \n",
       "\n",
       "                   orderdate            product  units  unitprice  \n",
       "0 2016-07-17 13:48:03.156566    Thriller record      2      13.27  \n",
       "1 2016-07-06 13:48:03.156596            Corolla     26   24458.69  \n",
       "2 2016-07-22 13:48:03.156618       Rubik’s Cube     41      15.79  \n",
       "3 2016-07-23 13:48:03.156638             iPhone     16     584.01  \n",
       "4 2016-07-16 13:48:03.156657  Harry Potter book      4      25.69  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data = pd.read_csv('./data/blooth_sales_data.csv',\n",
    "                         parse_dates=['birthday', 'orderdate'],\n",
    "                         dayfirst=True)\n",
    "sales_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**!** The date parse is US datew friendly! *MM/DD/YYYY*\n",
    "\n",
    "To use the more common international format for sure,<br>\n",
    "add \n",
    ">**`dayfirst=True`** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV import may be highly customized, <br>e.g.:\n",
    "\n",
    "* `date_parser` - which columns to parse.\n",
    "* `compression` - `pandas` hint compression of file, default: `infer`- auto discovery\n",
    "* `delimiter` - delimiter\n",
    "* `thousands`, `decimal` - thousands or decimal character\n",
    "* `encoding` - encoding of the file\n",
    "* `dtype`- target data type of column(s)\n",
    "* `header`- header number(s)\n",
    "* `skipfooter`- do not import the footer (e.g. summary line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
